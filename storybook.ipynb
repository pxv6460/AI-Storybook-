{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports for loading environment variables.\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import openai\n",
    "from openai.types import (\n",
    "    ErrorObject,\n",
    "    FunctionDefinition,\n",
    "    FunctionParameters,\n",
    "    ResponseFormatJSONObject,\n",
    "    ResponseFormatJSONSchema,\n",
    "    ResponseFormatText,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "GEMINI_MODEL = \"gemini-1.5-flash\"\n",
    "# Store the API key in a variable.\n",
    "GEMINI_API_KEY = \"AIzaSyC7S4KhCBWW8mn8_exr9J-MMTCuTFvrnHM\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'aiplatform' from 'google.cloud' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_google_genai\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ChatGoogleGenerativeAI\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01magents\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m initialize_agent, load_tools\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aiplatform\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mgoogle\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcloud\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maiplatform\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Model\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'aiplatform' from 'google.cloud' (unknown location)"
     ]
    }
   ],
   "source": [
    "# Additional imports for agent with built-in tools.\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain.agents import initialize_agent, load_tools\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "positional argument follows keyword argument (3403668505.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[15], line 8\u001b[1;36m\u001b[0m\n\u001b[1;33m    llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.8, tex)\u001b[0m\n\u001b[1;37m                                                                                                        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m positional argument follows keyword argument\n"
     ]
    }
   ],
   "source": [
    "def generate_madlib_prompt():\n",
    "  \"\"\"Generates a random Mad Lib prompt.\"\"\"\n",
    "\n",
    "  #endpoint = \"YOUR_ENDPOINT_NAME\"  # Replace with your endpoint name\n",
    "  #project = \"YOUR_PROJECT_ID\"  # Replace with your project ID\n",
    "  #region = \"YOUR_REGION\"  # Replace with your region\n",
    "\n",
    "  llm = ChatGoogleGenerativeAI(google_api_key=GEMINI_API_KEY, model=GEMINI_MODEL, temperature=0.8)\n",
    "\n",
    "  prompt = \"Write a 150-200 word, humorous Mad Lib story with 12 blanks. The blanks should be for 3 nouns, 3 verbs, 3 adjectives, 3 adverbs\"\n",
    "  response = llm.predict(instances=[{\"text\": prompt}])\n",
    "\n",
    "  return response.predictions[0][\"text\"]\n",
    "\n",
    "def play_madlib(prompt):\n",
    "  \"\"\"Plays the Mad Lib game with the given prompt.\"\"\"\n",
    "\n",
    "  words = []\n",
    "  for part_of_speech in [\"noun\", \"verb\", \"adjective\", \"adverb\", \"noun\"]:\n",
    "    word = input(f\"Enter a {part_of_speech}: \")\n",
    "    words.append(word)\n",
    "\n",
    "  # Replace placeholders in the prompt with the user's words\n",
    "  madlib_story = prompt.format(*words)\n",
    "\n",
    "  print(madlib_story)\n",
    "\n",
    "# Generate a random Mad Lib prompt\n",
    "prompt = generate_madlib_prompt()\n",
    "\n",
    "# Play the Mad Lib game\n",
    "play_madlib(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I recommend taking a walking tour of the Freedom Trail today. You can start at Boston Common and walk past sites like the Old North Church, Paul Revere's House, and the Boston Massacre site.\n"
     ]
    }
   ],
   "source": [
    "# Run the agent and print the result.\n",
    "result = agent.invoke(query)\n",
    "print(result[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m   \u001b[38;5;28mprint\u001b[39m(madlib_story)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Get a random Mad Lib prompt\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m prompt \u001b[38;5;241m=\u001b[39m generate_madlib_prompt()\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Play the Mad Lib game\u001b[39;00m\n\u001b[0;32m     34\u001b[0m play_madlib(prompt)\n",
      "Cell \u001b[1;32mIn[18], line 8\u001b[0m, in \u001b[0;36mgenerate_madlib_prompt\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Generates a random Mad Lib prompt.\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWrite a 150-200 word, humorous Mad Lib story with 12 blanks. The blanks should be for 3 nouns, 3 verbs, 3 adjectives, 3 adverbs the story can be as creative as you want it to be.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m response \u001b[38;5;241m=\u001b[39m openai\u001b[38;5;241m.\u001b[39mCompletion\u001b[38;5;241m.\u001b[39mcreate(\n\u001b[0;32m      9\u001b[0m   engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext-davinci-003\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     10\u001b[0m   prompt\u001b[38;5;241m=\u001b[39mprompt,\n\u001b[0;32m     11\u001b[0m   max_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m,\n\u001b[0;32m     12\u001b[0m   n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     13\u001b[0m   temperature\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.7\u001b[39m\n\u001b[0;32m     14\u001b[0m )\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\lib\\_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[1;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[1;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Completion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "# using OpenAI \n",
    "import openai\n",
    "\n",
    "def generate_madlib_prompt():\n",
    "  \"\"\"Generates a random Mad Lib prompt.\"\"\"\n",
    "\n",
    "  prompt = \"Write a 150-200 word, humorous Mad Lib story with 12 blanks. The blanks should be for 3 nouns, 3 verbs, 3 adjectives, 3 adverbs the story can be as creative as you want it to be.\"\n",
    "  response = openai.Completion.create(\n",
    "    engine=\"\",\n",
    "    prompt=prompt,\n",
    "    max_tokens=100,\n",
    "    n=1,\n",
    "    temperature=0.7\n",
    "  )\n",
    "  return response.choices[0].text.strip()\n",
    "\n",
    "def play_madlib(prompt):\n",
    "  \"\"\"Plays the Mad Lib game with the given prompt.\"\"\"\n",
    "\n",
    "  words = []\n",
    "  for i in range(12):\n",
    "    part_of_speech = input(f\"Enter word {i+1}: \")\n",
    "    words.append(part_of_speech)\n",
    "      \n",
    "  # Replace placeholders in the prompt with the user's words\n",
    "  madlib_story = prompt.format(*words)\n",
    "\n",
    "  print(madlib_story)\n",
    "\n",
    "# Get a random Mad Lib prompt\n",
    "prompt = generate_madlib_prompt()\n",
    "\n",
    "# Play the Mad Lib game\n",
    "play_madlib(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
