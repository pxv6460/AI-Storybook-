{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b03a1f03-24b9-4ac4-abf3-a34c9f7f8b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1aadab9b-1c18-4e44-bf6e-69e160f0f08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(\n",
    "  api_key=\"PASTE_KEY_HERE\",\n",
    "  project=\"proj_MRYMDgs0tsPON6n6syQuO5d6\",\n",
    ")\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": \"You are a story teller.\"},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write a short children's story about a girl and a bear. Limit your response to 300 words. Split your response into scenes. Give me your response in plain text without markdown.\"\n",
    "        }\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b057513e-70db-401b-8ae9-e018fa1361c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scene 1: The Curious Girl  \n",
      "Once upon a time in a sunny, green meadow, there lived a girl named Lily. Lily loved exploring and dreamed of going on adventures. One day, she wandered deeper into the woods than usual. She came across a sparkling river and sat on a rock to dip her toes. Suddenly, she heard a rustling sound behind her. \n",
      "\n",
      "Scene 2: A Big Surprise  \n",
      "Lily turned around and gasped! A big, fluffy bear stood there, looking just as surprised as she was. “Hello, I’m Benny,” the bear said. “I didn’t mean to scare you!” Lily, feeling brave, smiled back. “I’m Lily! Do you want to be friends?” Benny’s eyes sparkled with joy, and he nodded eagerly.\n",
      "\n",
      "Scene 3: An Adventure Begins  \n",
      "From that day on, Lily and Benny became the best of friends. They explored the woods together, climbing trees and watching butterflies. Benny showed Lily how to fish in the river, while Lily taught Benny how to dance. They laughed and played, sharing stories under the stars.\n",
      "\n",
      "Scene 4: The Stormy Night  \n",
      "One evening, a sudden storm swept through the valley. Lily was scared and ran to find Benny. He found her shivering under a tree. “Don’t worry,” he said, wrapping her in his warm fur. “We can wait it out together!” They huddled close as the rain poured, talking and telling stories until they fell asleep.\n",
      "\n",
      "Scene 5: Forever Friends  \n",
      "When the storm passed, the sun came back, shining brighter than ever. Lily and Benny had learned that true friendship means being there for each other, no matter what. From that day on, they continued to have many more adventures, always side by side, sharing the magic of their beautiful world. And they were best friends forever.\n"
     ]
    }
   ],
   "source": [
    "story = completion.choices[0].message.content\n",
    "print(story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "167727c6-b4de-4bce-bcea-fac7927d0b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The Curious Girl  \n",
      "Once upon a time in a sunny, green meadow, there lived a girl named Lily. Lily loved exploring and dreamed of going on adventures. One day, she wandered deeper into the woods than usual. She came across a sparkling river and sat on a rock to dip her toes. Suddenly, she heard a rustling sound behind her. \n",
      "\n",
      "\n",
      " A Big Surprise  \n",
      "Lily turned around and gasped! A big, fluffy bear stood there, looking just as surprised as she was. “Hello, I’m Benny,” the bear said. “I didn’t mean to scare you!” Lily, feeling brave, smiled back. “I’m Lily! Do you want to be friends?” Benny’s eyes sparkled with joy, and he nodded eagerly.\n",
      "\n",
      "\n",
      " An Adventure Begins  \n",
      "From that day on, Lily and Benny became the best of friends. They explored the woods together, climbing trees and watching butterflies. Benny showed Lily how to fish in the river, while Lily taught Benny how to dance. They laughed and played, sharing stories under the stars.\n",
      "\n",
      "\n",
      " The Stormy Night  \n",
      "One evening, a sudden storm swept through the valley. Lily was scared and ran to find Benny. He found her shivering under a tree. “Don’t worry,” he said, wrapping her in his warm fur. “We can wait it out together!” They huddled close as the rain poured, talking and telling stories until they fell asleep.\n",
      "\n",
      "\n",
      " Forever Friends  \n",
      "When the storm passed, the sun came back, shining brighter than ever. Lily and Benny had learned that true friendship means being there for each other, no matter what. From that day on, they continued to have many more adventures, always side by side, sharing the magic of their beautiful world. And they were best friends forever.\n"
     ]
    }
   ],
   "source": [
    "pattern = r\"Scene \\d+:\"\n",
    "scenes = re.split(pattern, story)\n",
    "\n",
    "for scene in scenes:\n",
    "    print(scene)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5c9e9680-1fe8-4b9d-b32a-3632d1a290b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-x5OjxFn700lF9KuBSleVdtVQ/user-PQjPlzFdJ8XT7Oo79wqGkctn/img-1F5YSS4LM2WTpszb1BfCwLLv.png?st=2024-11-21T00%3A38%3A43Z&se=2024-11-21T02%3A38%3A43Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-21T00%3A10%3A53Z&ske=2024-11-22T00%3A10%3A53Z&sks=b&skv=2024-08-04&sig=x/BT%2BrTD2PinJAgZe0Axy4NlOSdXQatqN1NovKJ3mkc%3D\n",
      "https://oaidalleapiprodscus.blob.core.windows.net/private/org-x5OjxFn700lF9KuBSleVdtVQ/user-PQjPlzFdJ8XT7Oo79wqGkctn/img-gkpJIpMSGgRHRMgCRaTyt21e.png?st=2024-11-21T00%3A38%3A54Z&se=2024-11-21T02%3A38%3A54Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=d505667d-d6c1-4a0a-bac7-5c84a87759f8&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2024-11-21T00%3A10%3A34Z&ske=2024-11-22T00%3A10%3A34Z&sks=b&skv=2024-08-04&sig=FPi4HdoHqFAN7P3jWWcVESbnn9p1BuNh1eLMrONTyKw%3D\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'code': 'rate_limit_exceeded', 'message': 'Rate limit exceeded for images per minute in organization org-x5OjxFn700lF9KuBSleVdtVQ. Limit: 5/1min. Current: 6/1min. Please visit https://platform.openai.com/docs/guides/rate-limits to learn how to increase your rate limit.', 'param': None, 'type': 'requests'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[45], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m scenes \u001b[38;5;241m=\u001b[39m scenes[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m scene \u001b[38;5;129;01min\u001b[39;00m scenes:\n\u001b[1;32m----> 3\u001b[0m     response \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mimages\u001b[38;5;241m.\u001b[39mgenerate(\n\u001b[0;32m      4\u001b[0m         prompt\u001b[38;5;241m=\u001b[39mscene,\n\u001b[0;32m      5\u001b[0m         n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m,\n\u001b[0;32m      6\u001b[0m         size\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m512x512\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      7\u001b[0m     )\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mdata[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39murl)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\resources\\images.py:264\u001b[0m, in \u001b[0;36mImages.generate\u001b[1;34m(self, prompt, model, n, quality, response_format, size, style, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    221\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[0;32m    222\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ImagesResponse:\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03m    Creates an image given a prompt.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[0;32m    263\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_post(\n\u001b[0;32m    265\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/images/generations\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    266\u001b[0m         body\u001b[38;5;241m=\u001b[39mmaybe_transform(\n\u001b[0;32m    267\u001b[0m             {\n\u001b[0;32m    268\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprompt\u001b[39m\u001b[38;5;124m\"\u001b[39m: prompt,\n\u001b[0;32m    269\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m: model,\n\u001b[0;32m    270\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m\"\u001b[39m: n,\n\u001b[0;32m    271\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquality\u001b[39m\u001b[38;5;124m\"\u001b[39m: quality,\n\u001b[0;32m    272\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse_format\u001b[39m\u001b[38;5;124m\"\u001b[39m: response_format,\n\u001b[0;32m    273\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msize\u001b[39m\u001b[38;5;124m\"\u001b[39m: size,\n\u001b[0;32m    274\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstyle\u001b[39m\u001b[38;5;124m\"\u001b[39m: style,\n\u001b[0;32m    275\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m\"\u001b[39m: user,\n\u001b[0;32m    276\u001b[0m             },\n\u001b[0;32m    277\u001b[0m             image_generate_params\u001b[38;5;241m.\u001b[39mImageGenerateParams,\n\u001b[0;32m    278\u001b[0m         ),\n\u001b[0;32m    279\u001b[0m         options\u001b[38;5;241m=\u001b[39mmake_request_options(\n\u001b[0;32m    280\u001b[0m             extra_headers\u001b[38;5;241m=\u001b[39mextra_headers, extra_query\u001b[38;5;241m=\u001b[39mextra_query, extra_body\u001b[38;5;241m=\u001b[39mextra_body, timeout\u001b[38;5;241m=\u001b[39mtimeout\n\u001b[0;32m    281\u001b[0m         ),\n\u001b[0;32m    282\u001b[0m         cast_to\u001b[38;5;241m=\u001b[39mImagesResponse,\n\u001b[0;32m    283\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1278\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[1;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1264\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1266\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1273\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1274\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m   1275\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[0;32m   1276\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[0;32m   1277\u001b[0m     )\n\u001b[1;32m-> 1278\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(cast_to, opts, stream\u001b[38;5;241m=\u001b[39mstream, stream_cls\u001b[38;5;241m=\u001b[39mstream_cls))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:955\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[1;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    953\u001b[0m     retries_taken \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m--> 955\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m    956\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m    957\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m    958\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m    959\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m    960\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m    961\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1045\u001b[0m         input_options,\n\u001b[0;32m   1046\u001b[0m         cast_to,\n\u001b[0;32m   1047\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1048\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1049\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1050\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1051\u001b[0m     )\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1094\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1095\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1096\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1097\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1098\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1099\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1044\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1042\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m remaining_retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m   1043\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m-> 1044\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retry_request(\n\u001b[0;32m   1045\u001b[0m         input_options,\n\u001b[0;32m   1046\u001b[0m         cast_to,\n\u001b[0;32m   1047\u001b[0m         retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1048\u001b[0m         response_headers\u001b[38;5;241m=\u001b[39merr\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mheaders,\n\u001b[0;32m   1049\u001b[0m         stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1050\u001b[0m         stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1051\u001b[0m     )\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1093\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[1;34m(self, options, cast_to, retries_taken, response_headers, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1089\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[0;32m   1090\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[0;32m   1091\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_request(\n\u001b[0;32m   1094\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   1095\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1096\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m   1097\u001b[0m     stream\u001b[38;5;241m=\u001b[39mstream,\n\u001b[0;32m   1098\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[0;32m   1099\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\openai\\_base_client.py:1059\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[1;34m(self, cast_to, options, retries_taken, stream, stream_cls)\u001b[0m\n\u001b[0;32m   1056\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m   1058\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m-> 1059\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[0;32m   1062\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[0;32m   1063\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1067\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39mretries_taken,\n\u001b[0;32m   1068\u001b[0m )\n",
      "\u001b[1;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'code': 'rate_limit_exceeded', 'message': 'Rate limit exceeded for images per minute in organization org-x5OjxFn700lF9KuBSleVdtVQ. Limit: 5/1min. Current: 6/1min. Please visit https://platform.openai.com/docs/guides/rate-limits to learn how to increase your rate limit.', 'param': None, 'type': 'requests'}}"
     ]
    }
   ],
   "source": [
    "scenes = [s for s in scenes if s]\n",
    "for scene in scenes:\n",
    "    response = client.images.generate(\n",
    "        prompt=scene,\n",
    "        n=2,\n",
    "        size=\"512x512\"\n",
    "    )\n",
    "    print(response.data[0].url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9886e2-ba24-40e9-a131-2014346f9f51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
